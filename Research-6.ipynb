{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "performances students require activities concept papers maps labs determine matching\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "determine activities students require projects designs labs papers concept maps\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "students require sets problem procedures activities discussions speeches readings films\n",
      "\n",
      "\n",
      "\n",
      "Assessment Topics DataFrame:\n",
      "        Topic 1     Topic 2      Topic 3\n",
      "0  performances   determine     students\n",
      "1      students  activities      require\n",
      "2       require    students         sets\n",
      "3    activities     require      problem\n",
      "4       concept    projects   procedures\n",
      "5        papers     designs   activities\n",
      "6          maps        labs  discussions\n",
      "7          labs      papers     speeches\n",
      "8     determine     concept     readings\n",
      "9      matching        maps        films\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Define Data\n",
    "texts = [\n",
    "    \"Activities such as case studies, critiques, labs, papers, projects, debates, or concept maps that require students to: discriminate or select relevant and irrelevant parts, determine how elements function together, determine bias, values, or underlying intent in presented material.\",\n",
    "    \"Activities such as papers, exams, problem sets, class discussions, or concept maps that require students to: summarize readings, films, or speeches, compare and contrast two or more theories, events, or processes.\",\n",
    "    \"Activities such as problem sets, performances, labs, prototyping, or simulations that require students to: use procedures to solve or complete familiar or unfamiliar tasks, determine which procedures are most appropriate for a given task.\",\n",
    "    \"Objective test items such as fill-in-the-blank, matching, labeling, or multiple-choice questions that require students to: recall or recognize terms, facts, and concepts.\",\n",
    "    \"Activities such as research projects, musical compositions, performances, essays, business plans, website designs, or set designs that require students to: make, build, design, or generate something new.\"\n",
    "]\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_text(texts):\n",
    "    stop_words = list(stopwords.words('english'))  # Convert to list\n",
    "    vectorizer = CountVectorizer(\n",
    "        stop_words=stop_words,\n",
    "        token_pattern=r'\\b\\w+\\b',  # Match whole words\n",
    "        lowercase=True\n",
    "    )\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    return X, vectorizer\n",
    "\n",
    "# Preprocess the Text\n",
    "X, vectorizer = preprocess_text(texts)\n",
    "\n",
    "# Apply LDA\n",
    "n_topics = 3  # Adjust the number of topics as needed\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Display Topics\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx + 1}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        print(\"\\n\")\n",
    "\n",
    "no_top_words = 10\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "display_topics(lda, feature_names, no_top_words)\n",
    "\n",
    "# Match Topics to Assessments\n",
    "topic_assessments = {}\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    topic_assessments[f\"Topic {topic_idx + 1}\"] = [\n",
    "        feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]\n",
    "    ]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_assessments = pd.DataFrame.from_dict(topic_assessments, orient='index').transpose()\n",
    "print(\"\\nAssessment Topics DataFrame:\")\n",
    "print(df_assessments)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
