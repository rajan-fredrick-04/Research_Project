{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloom's Taxonomy Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajan\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import tabula\n",
    "import pandas as pd\n",
    "import camelot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table extracted and saved to 'output_table.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Path to your PDF file\n",
    "pdf_path = 'Blooms-Taxonomy-Handout.pdf'\n",
    "\n",
    "# Extract tables from the PDF\n",
    "tables = camelot.read_pdf(pdf_path, pages='all')\n",
    "\n",
    "# Convert the first table to a DataFrame and export it to Excel\n",
    "if len(tables) > 0:\n",
    "    df = tables[0].df  # Extract the first table as a DataFrame\n",
    "    columns=df.iloc[0]\n",
    "    column_names=columns[0].split('\\n')\n",
    "    df.columns=column_names\n",
    "    df = df.drop(0) \n",
    "    df = df.replace('\\n', '', regex=True)\n",
    "    df.to_excel('Blooms_index.xlsx', index=False)\n",
    "    print(f\"Table extracted and saved to 'output_table.xlsx'\")\n",
    "else:\n",
    "    print(\"No table found in the PDF.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course Outcomes Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered course outcomes tables have been saved to 'course_outcomes_combined_single_sheet.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pdf_path = 'MDS2024_25.pdf'\n",
    "\n",
    "# Extract all tables from the PDF with the lattice option to handle table borders better\n",
    "try:\n",
    "    tables_json = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True, output_format=\"json\", encoding='ISO-8859-1', lattice=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error reading PDF: {e}\")\n",
    "    tables_json = []  # Initialize as empty if reading fails\n",
    "\n",
    "# Regular expression pattern to identify \"Course Outcomes\" table\n",
    "pattern = re.compile(r\"Course Outcomes\", re.IGNORECASE)\n",
    "\n",
    "# Filter JSON data for tables with \"Course Outcomes\"\n",
    "course_outcomes_tables = []\n",
    "for table_json in tables_json:\n",
    "    try:\n",
    "        # Convert JSON to DataFrame\n",
    "        table_data = [[cell['text'] for cell in row] for row in table_json['data']]\n",
    "        table = pd.DataFrame(table_data)\n",
    "        \n",
    "        # Check for the pattern in the DataFrame content\n",
    "        if table.apply(lambda row: row.astype(str).str.contains(pattern).any(), axis=1).any():\n",
    "            # Set the first row as header if it matches the expected format\n",
    "            if 'No.' in table.iloc[0].values[0] and 'Course Outcomes' in table.iloc[0].values[1]:\n",
    "                table.columns = table.iloc[0]  # Set first row as header\n",
    "                table = table.drop(0).reset_index(drop=True)  # Drop the header row from data\n",
    "            \n",
    "            # Standardize column names\n",
    "            table.columns = ['No', 'Course Outcomes', 'LRNG Needs', 'Unused_1', 'Unused_2'][:table.shape[1]]\n",
    "            \n",
    "            # Drop unnecessary columns by name\n",
    "            table = table.drop(columns=['LRNG Needs', 'Unused_1', 'Unused_2'], errors='ignore')\n",
    "            \n",
    "            # Fix merged words in 'Course Outcomes' by adding spaces before capital letters or numbers\n",
    "            def fix_merged_words(text):\n",
    "                # Add spaces between lowercase-uppercase or letter-number transitions\n",
    "                return re.sub(r'(?<=[a-z])(?=[A-Z0-9])', ' ', text)\n",
    "            \n",
    "            table['Course Outcomes'] = table['Course Outcomes'].apply(lambda x: fix_merged_words(x))\n",
    "\n",
    "            # Add the table to the list\n",
    "            course_outcomes_tables.append(table)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing table JSON data: {e}\")\n",
    "\n",
    "# Concatenate all \"Course Outcomes\" tables into a single DataFrame\n",
    "if course_outcomes_tables:\n",
    "    combined_df = pd.concat(course_outcomes_tables, ignore_index=True)\n",
    "    \n",
    "    # Drop duplicate rows\n",
    "    combined_df = combined_df.drop_duplicates()\n",
    "    \n",
    "    # Add \"Verbs\" and \"Assessments\" columns with empty values\n",
    "    combined_df['Verbs'] = \"\"       # Or provide a default value if needed\n",
    "    combined_df['Assessments'] = \"\"  # Or provide a default value if needed\n",
    "    \n",
    "    # Save to Excel file\n",
    "    combined_df.to_excel(\"course_outcomes.xlsx\", index=False)\n",
    "    print(\"Filtered course outcomes tables have been saved to 'course_outcomes_combined_single_sheet.xlsx'\")\n",
    "else:\n",
    "    print(\"No tables containing 'Course Outcomes' found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb Assessments Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the Course Outcomes Dataframe in df_co\n",
    "df_co=combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>Course Outcomes</th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CO1</td>\n",
       "      <td>Understand the essence of research and the\\rim...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CO2</td>\n",
       "      <td>Explore the fundamental concepts of data science</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO3</td>\n",
       "      <td>Understand various machine learning algorithms...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CO4</td>\n",
       "      <td>Learn to think through the ethics surrounding ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CO5</td>\n",
       "      <td>Create scientific reports according to specifi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>CO4</td>\n",
       "      <td>Designcomputationalexperimentsfortrainingandev...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>CO1</td>\n",
       "      <td>Understand the fundamental principles of image...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>CO2</td>\n",
       "      <td>Develop proficiency in image enhancement and s...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>CO3</td>\n",
       "      <td>Develop skills in object detection and recogni...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>CO4</td>\n",
       "      <td>Apply the image and video analysis approaches ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      No                                    Course Outcomes Verbs Assessments\n",
       "0    CO1  Understand the essence of research and the\\rim...                  \n",
       "1    CO2   Explore the fundamental concepts of data science                  \n",
       "2    CO3  Understand various machine learning algorithms...                  \n",
       "3    CO4  Learn to think through the ethics surrounding ...                  \n",
       "4    CO5  Create scientific reports according to specifi...                  \n",
       "..   ...                                                ...   ...         ...\n",
       "128  CO4  Designcomputationalexperimentsfortrainingandev...                  \n",
       "129  CO1  Understand the fundamental principles of image...                  \n",
       "130  CO2  Develop proficiency in image enhancement and s...                  \n",
       "131  CO3  Develop skills in object detection and recogni...                  \n",
       "132  CO4  Apply the image and video analysis approaches ...                  \n",
       "\n",
       "[133 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the Data Frame for checking the result\n",
    "df_co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indentify the Verbs from the Course Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_outcomes=[]\n",
    "for i in range(len(df_co)):\n",
    "    data=df_co['Course Outcomes'].iloc[i]\n",
    "    course_outcomes.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Understand the essence of research and the\\rimportance of research methods and methodology',\n",
       " 'Explore the fundamental concepts of data science',\n",
       " 'Understand various machine learning algorithms used in data science process',\n",
       " 'Learn to think through the ethics surrounding privacy, data sharing and algorithmi\\rdecision- making',\n",
       " 'Create scientific reports according to specified standards',\n",
       " 'able to understand the concept of the random variable and expectation for discrete\\rand continuous data',\n",
       " 'evaluate condition probabilities and conditional expectations',\n",
       " 'gain the knowledge of applications of discrete distributions in Data Science',\n",
       " 'identify the applications of continuous distributions in Data Science',\n",
       " 'apply Chebychevs inequality to verify the convergence of sequence in probability',\n",
       " 'Understand the fundamentals of programming languages.',\n",
       " 'Understand the design paradigms of programming languages.',\n",
       " 'To examine expressions, subprograms and their parameters.',\n",
       " 'Demonstrate, present and visualize data in various forms, statistically.',\n",
       " 'Understand and apply descriptive statistics.',\n",
       " 'Evaluation of probabilities for various kinds of random events.',\n",
       " 'Demonstrate the Basic file, directory commands',\n",
       " 'Understand the Unix system environment',\n",
       " 'Apply shell programming concepts to solve given problem',\n",
       " 'Demonstrate the use of built-in objects of Python',\n",
       " 'Demonstrate significant experience with Python program development environment',\n",
       " 'Implement numerical programming, data handling and visualization through Num Py,\\rPandas and Matplot Lib modules.',\n",
       " 'Demonstrate the data management using excel features.',\n",
       " 'Analyze the given problem and solve using Excel.',\n",
       " 'Infer the building blocks of excel, excel shortcuts, sample data creation',\n",
       " 'Design new algorithms and analyze their asymptotic and absolute runtime and memory\\rdemands.',\n",
       " 'Apply classical sorting, searching, optimization and graph algorithms.',\n",
       " 'Understand basic techniques for designing algorithms, including the techniques of recursion,\\rdivide-and-conquer, greedy algorithm etc.',\n",
       " 'Understand the mathematical criterion for deciding whether an algorithm is efficient and\\rknow many practically important problems that do not admit any efficient algorithms.',\n",
       " 'Demonstrate various databases and compose effective queries',\n",
       " 'Understanding the process of OLAP system construction',\n",
       " 'Develop applications using Relational and No SQL databases.',\n",
       " 'Demonstrate the concepts of population and samples',\n",
       " 'Apply the idea of sampling distribution of different statistics in\\rtesting of hypothesis',\n",
       " 'Estimate the unknown population parameters using the concepts of\\rpoint and interval estimations using R.',\n",
       " 'Test the hypothesis using nonparametric tests for real world\\rproblems using R.',\n",
       " 'Apply Java Script, HTML5, and CSS3 effectively to create interactive and\\rdynamic websites',\n",
       " 'Describethemaintechnologiesandmethodscurrentlyusedincreating\\radvanced web applications',\n",
       " 'Designwebsitesusingappropriatesecurityprinciples,focusingspecifically\\ron the vulnerabilities inherent in common web implementations',\n",
       " 'Create modern web applications using MEAN',\n",
       " 'Develop an understanding of best practices for writing clean, maintainable, and\\rwell-documented code',\n",
       " 'Apply object-oriented programming structures in Java to solve problems',\n",
       " 'Develop sustainable and innovative solutions for real-time problems.',\n",
       " 'Understand the basic principles of machine learning techniques.',\n",
       " 'Understand how machine learning problems are formulated and solved',\n",
       " 'Apply machine learning algorithms to solve real world problems.',\n",
       " 'Formulate the linear regression model and its application to real data.',\n",
       " 'Understand and identify the various assumptions of linear regression models.',\n",
       " 'Identify the correct model using model selection and variable selection criteria.',\n",
       " 'Ability to use and understand generalizations of the linear model to binary and\\rcount data.',\n",
       " 'Describe the categorical response',\n",
       " 'Identify tests for contingency tables',\n",
       " 'Apply regression models for categorical response variables',\n",
       " 'Analyse contingency tables using log-linear models',\n",
       " 'Understandmultivariatedatastructure,multinomial,andmultivariatenorma\\rdistribution.',\n",
       " 'Apply likelihood Ratio tests for multivariate normal proportions',\n",
       " 'Analyze multivariate data using (MANOVA) of one and two-way classified data',\n",
       " 'Understand the core concepts of the cloud computing paradigm.',\n",
       " 'Applyfundamentalconceptsofcloudinfrastructures,cloudstorageandi\\rstorage systems such as Amazon S3 and HDFS.',\n",
       " 'Analyze various cloud programming models and apply them to solve problems\\ron the cloud.',\n",
       " 'Analyse data to identify trends, patterns, outliers',\n",
       " 'Evaluate Charts which could present the insight effectively',\n",
       " 'Present Data Insights using Charts and Dashboards',\n",
       " 'Ability to approach and analyse univariate time series',\n",
       " 'Ability to differentiate between various time series models like AR, MA, ARMA and\\rARIMA models',\n",
       " 'Evaluate stationary and non-stationary time series models',\n",
       " 'Able to forecast future observations of the time series',\n",
       " 'Understand the fundamental concepts of Artificial Neural Networks (ANN) and their\\revolution,Analyzethetheoryandarchitectureofshallowneuralnetworks,\\rimplementing learning factors in Back-Propagation Networks for effective training.',\n",
       " 'Understand the fundamental concepts of Artificial Neural Networks (ANN) and thei',\n",
       " 'evolution',\n",
       " 'Applyconvolutionaloperationsforimagerecognitionin Convolutional Neural\\rNetworks (CNN) and implement different CNN architectures.',\n",
       " 'Evaluatethechallengesintraining Recurrent Neural Networks (RNN) and create an\\rimplementationof Long Short-Term Memory(LSTM) forsequentialdata analysis.\\rUnderstand and apply features of Auto encoders and Restricted Boltzmann Machines\\r(RBM)for efficientunsupervisedfeaturelearning.Apply Neural network models to\\rsolve real time problems.',\n",
       " 'Understand the concept and importance of Web analytics in an organization and the\\rrole of Web analytic in collecting, analyzing and reporting website traffic.',\n",
       " 'Identify key tools and diagnostics associated with Web analytics.',\n",
       " 'Exploreeffective Webanalyticsstrategiesandimplementationand Understand the\\rimportance of web analytic as a tool for e-Commerce, business research, and market\\rresearch.',\n",
       " 'Illustrate the process of constructing a data flow for linking Io T system or device data\\rto the cloud utilizing particular formats.',\n",
       " 'Illustrate the process of constructing a data flow for linking Io T system or device data',\n",
       " 'to the cloud utilizing particular formats.',\n",
       " 'Describe the utilization of big data tools in distributed computing for processing Io T\\rdata',\n",
       " 'Employ algorithms to analyze Io T data patterns and extract intelligence',\n",
       " 'Understand word and sentence level analysis',\n",
       " 'Apply Vector semantics and embeddings for representation of text',\n",
       " 'Design text based information retrieval systems',\n",
       " 'Analyze NLP applications for real world data',\n",
       " 'Understandingof Graph Theory Fundamentals: Students will demonstrate a\\rsolid understanding of fundamental concepts in graph theory.',\n",
       " 'Proficiency in Graph Algorithms: Students will be proficient in implementing\\rand applying common graph algorithms.',\n",
       " 'Applicationof Community Detection Techniques:Studentswillbeableto\\rapply community detection algorithms.',\n",
       " 'Knowledgeof Graph-Based Machine Learning:Studentswillgain\\rknowledge of graph-based machine learning techniques and understand their\\rapplications.',\n",
       " 'Practical Application of Graph Analytics: Students will apply graph analytics\\rtechniques to real-world datasets and problems.',\n",
       " 'Demonstrate proficiency in developing web applications',\n",
       " 'Show proficiency in Integrating Data Science Techniques with Web Development',\n",
       " 'Perform Effective Problem-solving and Decision-making Skills',\n",
       " 'Gain Advanced Understanding of Data Ethics and Best Practices',\n",
       " 'Understand the Big Data concepts in real time scenario',\n",
       " 'Identify different types of Hadoop architecture',\n",
       " 'Demonstrate an ability to use Hadoop framework for processing Big Data for Analytics',\n",
       " 'Analyze the Big data under Spark architecture',\n",
       " 'Demonstrate the programming of Big data using Hive and Pig environments',\n",
       " 'Demonstrate Simple and multiple Econometric models',\n",
       " 'Interpret the models adequacy through various methods',\n",
       " 'Demonstrate simultaneous Linear Equations model.',\n",
       " 'Demonstrate contemporary trends in estimation of econometrics models.',\n",
       " 'Identify Bayesian methods for a binomial proportion.',\n",
       " 'Analyse normal distributed data in the Bayesian framework.',\n",
       " 'Compare Bayesian methods and frequentist methods.',\n",
       " 'Demonstrate the understanding of basic concepts of biostatistics and the process\\rinvolved in the scientific method of research.',\n",
       " 'Identify how the data can be appropriately organized and displayed.',\n",
       " 'Analyze and interpret the data based on the discrete and continuous probability\\rdistributions.Apply parametric and non-parametric methods of statistical\\rdata analysis.',\n",
       " 'Understand the concepts of Epidemiology and Demography',\n",
       " 'Basic understanding of evolutionary computing concepts and techniques.',\n",
       " 'Classify relevant real-time problems for the applications of evolutionary algorithms.',\n",
       " 'Design solutions using evolutionary algorithms.',\n",
       " 'Understand the basics of quantum mechanics and quantum computing.',\n",
       " 'Implement and analyze quantum machine learning algorithms using Qiskit',\n",
       " 'Apply quantum algorithms to solve machine learning problems.',\n",
       " 'Critically evaluate the advantages and limitations of quantum machine learning approaches.',\n",
       " 'Grasp the fundamental concepts of Reinforcement Learning, including Markov\\rDecision Processes, states, actions, rewards, and key components of RL System.',\n",
       " 'Able to apply dynamic programming methods',\n",
       " 'Develop skills in model-free prediction using Monte Carlo methods.',\n",
       " 'Comprehendvariousexplorationstrategiessuchasepsilon-greedy,softmax\\rexploration, and Upper Confidence Bound (UCB)',\n",
       " 'Apply and understand Policy Gradient method in Reinforcement Learning\\rEnvironment',\n",
       " 'Understand fundamental geospatial data analysis techniques',\n",
       " 'Apply geospatial data visualization methods to represent spatial patterns and trends',\n",
       " 'Apply different geospatial analysis techniques .',\n",
       " 'Implement geospatial data analytics workflows using relevant software tools.',\n",
       " 'Understand how to evaluate models generated from data',\n",
       " 'Understand public-domain biological datasets',\n",
       " 'Analyze genomics using decision trees, and random forests',\n",
       " 'Designcomputationalexperimentsfortrainingandevaluatingmachine learning\\rmethods for solving bioinformatics problems',\n",
       " 'Understand the fundamental principles of image and video analysis',\n",
       " 'Develop proficiency in image enhancement and segmentation',\n",
       " 'Develop skills in object detection and recognition',\n",
       " 'Apply the image and video analysis approaches to solve real world problems']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs=['VB','VBP','VBD','VBG','VBN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_verbs=[]\n",
    "for i in range(0,len(course_outcomes)):\n",
    "    review=course_outcomes[i]\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=nltk.pos_tag(review)\n",
    "    review=[word for word,tag in review if tag in verbs]\n",
    "    course_verbs.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['understand'],\n",
       " [],\n",
       " ['learning', 'used'],\n",
       " ['think', 'surrounding'],\n",
       " ['according', 'specified'],\n",
       " ['understand'],\n",
       " [],\n",
       " ['gain'],\n",
       " ['identify'],\n",
       " ['verify'],\n",
       " ['understand', 'programming'],\n",
       " ['understand', 'programming'],\n",
       " ['examine'],\n",
       " ['visualize'],\n",
       " ['apply'],\n",
       " [],\n",
       " ['demonstrate'],\n",
       " ['understand'],\n",
       " ['programming', 'solve', 'given'],\n",
       " ['demonstrate'],\n",
       " [],\n",
       " [],\n",
       " ['demonstrate', 'using'],\n",
       " ['given', 'solve', 'using'],\n",
       " ['infer'],\n",
       " ['analyze'],\n",
       " [],\n",
       " ['designing', 'including'],\n",
       " ['understand', 'deciding', 'know', 'do', 'admit'],\n",
       " [],\n",
       " ['understanding'],\n",
       " ['develop', 'using'],\n",
       " ['demonstrate'],\n",
       " ['apply', 'sampling', 'testing'],\n",
       " ['estimate', 'using', 'using'],\n",
       " ['using', 'using'],\n",
       " ['create'],\n",
       " ['describethemaintechnologiesandmethodscurrentlyusedincreating'],\n",
       " ['inherent'],\n",
       " ['using'],\n",
       " ['develop', 'writing'],\n",
       " ['programming', 'solve'],\n",
       " ['develop'],\n",
       " ['understand'],\n",
       " ['understand', 'are', 'formulated', 'solved'],\n",
       " ['learning', 'solve'],\n",
       " ['formulate'],\n",
       " ['identify'],\n",
       " ['identify', 'using'],\n",
       " ['use', 'understand'],\n",
       " ['describe'],\n",
       " [],\n",
       " ['apply'],\n",
       " ['using'],\n",
       " [],\n",
       " [],\n",
       " ['using', 'classified'],\n",
       " ['understand', 'computing'],\n",
       " [],\n",
       " ['apply', 'solve'],\n",
       " ['identify'],\n",
       " ['present'],\n",
       " ['using'],\n",
       " ['analyse'],\n",
       " ['differentiate'],\n",
       " [],\n",
       " ['forecast'],\n",
       " ['understand', '(ann)', 'implementing', 'learning'],\n",
       " ['understand', '(ann)', 'thei'],\n",
       " [],\n",
       " ['(cnn)'],\n",
       " ['evaluatethechallengesintraining', '(rnn)', 'create', 'analysis.', 'solve'],\n",
       " ['understand', 'reporting'],\n",
       " ['identify', 'associated'],\n",
       " ['understand'],\n",
       " ['illustrate', 'constructing', 'linking', 'utilizing'],\n",
       " ['illustrate', 'constructing', 'linking'],\n",
       " ['utilizing'],\n",
       " ['describe', 'computing', 'processing'],\n",
       " ['analyze'],\n",
       " [],\n",
       " [],\n",
       " ['based'],\n",
       " [],\n",
       " ['demonstrate'],\n",
       " ['be', 'implementing', 'applying'],\n",
       " ['apply'],\n",
       " ['knowledgeof', 'learning', 'understand'],\n",
       " ['apply'],\n",
       " ['developing'],\n",
       " ['integrating'],\n",
       " ['perform'],\n",
       " ['advanced'],\n",
       " ['understand'],\n",
       " ['identify'],\n",
       " ['demonstrate', 'use', 'processing'],\n",
       " [],\n",
       " ['demonstrate', 'using'],\n",
       " [],\n",
       " ['interpret', 'adequacy'],\n",
       " ['model.'],\n",
       " [],\n",
       " ['identify'],\n",
       " ['distributed'],\n",
       " [],\n",
       " ['demonstrate', 'involved'],\n",
       " ['identify', 'be', 'organized', 'displayed.'],\n",
       " ['interpret', 'based'],\n",
       " ['understand'],\n",
       " ['computing'],\n",
       " ['classify'],\n",
       " ['using'],\n",
       " ['understand'],\n",
       " ['learning', 'using'],\n",
       " ['solve', 'learning'],\n",
       " ['evaluate', 'learning'],\n",
       " ['grasp', 'including'],\n",
       " ['apply'],\n",
       " ['develop', 'using'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " ['represent'],\n",
       " [],\n",
       " ['using'],\n",
       " ['understand', 'evaluate', 'generated'],\n",
       " [],\n",
       " ['using'],\n",
       " ['learning', 'solving'],\n",
       " ['understand'],\n",
       " ['develop'],\n",
       " ['develop'],\n",
       " ['apply', 'solve']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Blooms Taxonomy Pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blooms=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level:</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Examples of Appropriate Assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Remembering: can the student recall or remembe...</td>\n",
       "      <td>Recall Recognize Identify</td>\n",
       "      <td>Objective test items such as fill-in-the-blank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Understanding: can the student explain ideas o...</td>\n",
       "      <td>Interpret Exemplify Classify Summarize Infer C...</td>\n",
       "      <td>Activities such as papers, exams, problem sets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Applying: can the student use the information ...</td>\n",
       "      <td>Apply Execute Implement</td>\n",
       "      <td>Activities such as problem sets, performances,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Analyzing: can the student distinguish between...</td>\n",
       "      <td>Analyze Differentiate Organize Attribute</td>\n",
       "      <td>Activities such as case studies, critiques, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Evaluating: can the student justify a stand or...</td>\n",
       "      <td>Evaluate Check Critique Assess</td>\n",
       "      <td>Activities such as journals, diaries, critique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Creating: can the student create new product o...</td>\n",
       "      <td>Create Generate Plan Produce Design</td>\n",
       "      <td>Activities such as research projects, musical ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Level:   \\\n",
       "1  Remembering: can the student recall or remembe...   \n",
       "2  Understanding: can the student explain ideas o...   \n",
       "3  Applying: can the student use the information ...   \n",
       "4  Analyzing: can the student distinguish between...   \n",
       "5  Evaluating: can the student justify a stand or...   \n",
       "6  Creating: can the student create new product o...   \n",
       "\n",
       "                                               Verb   \\\n",
       "1                          Recall Recognize Identify   \n",
       "2  Interpret Exemplify Classify Summarize Infer C...   \n",
       "3                            Apply Execute Implement   \n",
       "4           Analyze Differentiate Organize Attribute   \n",
       "5                     Evaluate Check Critique Assess   \n",
       "6                Create Generate Plan Produce Design   \n",
       "\n",
       "                 Examples of Appropriate Assessments  \n",
       "1  Objective test items such as fill-in-the-blank...  \n",
       "2  Activities such as papers, exams, problem sets...  \n",
       "3  Activities such as problem sets, performances,...  \n",
       "4  Activities such as case studies, critiques, la...  \n",
       "5  Activities such as journals, diaries, critique...  \n",
       "6  Activities such as research projects, musical ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blooms['Verb '] = df_blooms['Verb '].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                        [Recall, Recognize, Identify]\n",
       "2    [Interpret, Exemplify, Classify, Summarize, In...\n",
       "3                          [Apply, Execute, Implement]\n",
       "4        [Analyze, Differentiate, Organize, Attribute]\n",
       "5                  [Evaluate, Check, Critique, Assess]\n",
       "6            [Create, Generate, Plan, Produce, Design]\n",
       "Name: Verb , dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blooms['Verb ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_course_verbs = [verb[0] for verb in course_verbs if verb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['understand',\n",
       " 'learning',\n",
       " 'think',\n",
       " 'according',\n",
       " 'understand',\n",
       " 'gain',\n",
       " 'identify',\n",
       " 'verify',\n",
       " 'understand',\n",
       " 'understand',\n",
       " 'examine',\n",
       " 'visualize',\n",
       " 'apply',\n",
       " 'demonstrate',\n",
       " 'understand',\n",
       " 'programming',\n",
       " 'demonstrate',\n",
       " 'demonstrate',\n",
       " 'given',\n",
       " 'infer',\n",
       " 'analyze',\n",
       " 'designing',\n",
       " 'understand',\n",
       " 'understanding',\n",
       " 'develop',\n",
       " 'demonstrate',\n",
       " 'apply',\n",
       " 'estimate',\n",
       " 'using',\n",
       " 'create',\n",
       " 'describethemaintechnologiesandmethodscurrentlyusedincreating',\n",
       " 'inherent',\n",
       " 'using',\n",
       " 'develop',\n",
       " 'programming',\n",
       " 'develop',\n",
       " 'understand',\n",
       " 'understand',\n",
       " 'learning',\n",
       " 'formulate',\n",
       " 'identify',\n",
       " 'identify',\n",
       " 'use',\n",
       " 'describe',\n",
       " 'apply',\n",
       " 'using',\n",
       " 'using',\n",
       " 'understand',\n",
       " 'apply',\n",
       " 'identify',\n",
       " 'present',\n",
       " 'using',\n",
       " 'analyse',\n",
       " 'differentiate',\n",
       " 'forecast',\n",
       " 'understand',\n",
       " 'understand',\n",
       " '(cnn)',\n",
       " 'evaluatethechallengesintraining',\n",
       " 'understand',\n",
       " 'identify',\n",
       " 'understand',\n",
       " 'illustrate',\n",
       " 'illustrate',\n",
       " 'utilizing',\n",
       " 'describe',\n",
       " 'analyze',\n",
       " 'based',\n",
       " 'demonstrate',\n",
       " 'be',\n",
       " 'apply',\n",
       " 'knowledgeof',\n",
       " 'apply',\n",
       " 'developing',\n",
       " 'integrating',\n",
       " 'perform',\n",
       " 'advanced',\n",
       " 'understand',\n",
       " 'identify',\n",
       " 'demonstrate',\n",
       " 'demonstrate',\n",
       " 'interpret',\n",
       " 'model.',\n",
       " 'identify',\n",
       " 'distributed',\n",
       " 'demonstrate',\n",
       " 'identify',\n",
       " 'interpret',\n",
       " 'understand',\n",
       " 'computing',\n",
       " 'classify',\n",
       " 'using',\n",
       " 'understand',\n",
       " 'learning',\n",
       " 'solve',\n",
       " 'evaluate',\n",
       " 'grasp',\n",
       " 'apply',\n",
       " 'develop',\n",
       " 'represent',\n",
       " 'using',\n",
       " 'understand',\n",
       " 'using',\n",
       " 'learning',\n",
       " 'understand',\n",
       " 'develop',\n",
       " 'develop',\n",
       " 'apply']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_course_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_df_verbs = [' '.join(verbs) for verbs in df_blooms['Verb ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recall Recognize Identify',\n",
       " 'Interpret Exemplify Classify Summarize Infer Compare Explain',\n",
       " 'Apply Execute Implement',\n",
       " 'Analyze Differentiate Organize Attribute',\n",
       " 'Evaluate Check Critique Assess',\n",
       " 'Create Generate Plan Produce Design']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_df_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "blooms_verbs=[]\n",
    "for i in range(len(flattened_df_verbs)):\n",
    "    review=flattened_df_verbs[i]\n",
    "    review=review.split()\n",
    "    blooms_verbs.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Recall', 'Recognize', 'Identify'],\n",
       " ['Interpret',\n",
       "  'Exemplify',\n",
       "  'Classify',\n",
       "  'Summarize',\n",
       "  'Infer',\n",
       "  'Compare',\n",
       "  'Explain'],\n",
       " ['Apply', 'Execute', 'Implement'],\n",
       " ['Analyze', 'Differentiate', 'Organize', 'Attribute'],\n",
       " ['Evaluate', 'Check', 'Critique', 'Assess'],\n",
       " ['Create', 'Generate', 'Plan', 'Produce', 'Design']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blooms_verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_va = pd.DataFrame(columns=[\"Verbs\", \"Assessments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "verbs = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']  # POS tags for verbs\n",
    "\n",
    "# Function to extract verbs from the course outcomes\n",
    "def extract_verbs(course_outcomes):\n",
    "    course_verbs = []\n",
    "    for outcome in course_outcomes:\n",
    "        words = outcome.split()\n",
    "        tagged_words = nltk.pos_tag(words)\n",
    "        verbs_in_outcome = [word for word, tag in tagged_words if tag in verbs]\n",
    "        course_verbs.append(verbs_in_outcome)\n",
    "    return course_verbs\n",
    "\n",
    "# Function to get SpaCy word vectors for words\n",
    "def get_word_vector(word):\n",
    "    doc = nlp(word)\n",
    "    if doc.has_vector:\n",
    "        return doc.vector\n",
    "    else:\n",
    "        return np.zeros(nlp.vocab.vectors_length)  # Return zero vector if word not in vocab\n",
    "\n",
    "# Convert course verbs to vectors (assuming course_verbs is a list of verb lists)\n",
    "flattened_course_verbs = [verb for sublist in course_verbs for verb in sublist]\n",
    "course_verb_vectors = np.array([get_word_vector(verb) for verb in flattened_course_verbs])\n",
    "\n",
    "# Set a similarity threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Assuming 'blooms_verbs' is your list of Bloom's verbs categories (from your example)\n",
    "matching_assessments = {}\n",
    "\n",
    "# Iterate over course verbs and find matching Bloom's verbs & assessments\n",
    "\n",
    "\n",
    "# Iterate over course verbs and find matching Bloom's verbs & assessments\n",
    "for i, course_verb in enumerate(flattened_course_verbs):\n",
    "    matching_assessments[course_verb] = []\n",
    "    \n",
    "    # Compare with each Bloom's category\n",
    "    for cat_index, blooms_category in enumerate(blooms_verbs):\n",
    "        blooms_verb_vectors = np.array([get_word_vector(verb) for verb in blooms_category])\n",
    "        \n",
    "        # Calculate cosine similarity between the course verb and each Bloom's verb\n",
    "        sim_scores = cosine_similarity([course_verb_vectors[i]], blooms_verb_vectors).flatten()\n",
    "        \n",
    "        # Check if any similarity score in this category is above the threshold\n",
    "        if any(score > threshold for score in sim_scores):\n",
    "            matching_assessments[course_verb].append(df_blooms.iloc[cat_index]['Examples of Appropriate Assessments'])\n",
    "\n",
    "    # Create a new DataFrame for the current mapping\n",
    "    new_row = pd.DataFrame({\"Verbs\": [course_verb], \"Assessments\": [matching_assessments[course_verb]]})\n",
    "    \n",
    "    # Concatenate the new row with the existing DataFrame\n",
    "    df_va = pd.concat([df_va, new_row], ignore_index=True)\n",
    "\n",
    "# Define a function to handle nested lists and ensure uniqueness\n",
    "def aggregate_unique_assessments(assessments):\n",
    "    # Flatten and deduplicate all lists in the column\n",
    "    unique_items = set(item for sublist in assessments for item in sublist)\n",
    "    return list(unique_items)\n",
    "\n",
    "# Group by \"Verbs\" and apply the aggregation function\n",
    "grouped_df = df_va.groupby(\"Verbs\", as_index=False).agg({\n",
    "    \"Assessments\": aggregate_unique_assessments\n",
    "})\n",
    "\n",
    "# Display the grouped DataFrame\n",
    "grouped_df\n",
    "grouped_df.to_excel('Verbs-Assesments Grouped.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
